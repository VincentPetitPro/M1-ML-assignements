{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de ML - hands-on 4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VincentPetitPro/M1-ML-assignements/blob/master/Copie_de_ML_hands_on_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BavpJykakMMw"
      },
      "source": [
        "#Hands-on 4 - SVM - Logistic regression - metrics\n",
        "\n",
        "In this assignment you will train several models and evaluate how effectively they predict instances of fraud using data based on [this dataset from Kaggle](https://www.kaggle.com/dalpozz/creditcardfraud).\n",
        " \n",
        "Each row in `fraud_data.csv` corresponds to a credit card transaction. Features include confidential variables `V1` through `V28` as well as `Amount` which is the amount of the transaction. \n",
        " \n",
        "The target is stored in the `class` column, where a value of 1 corresponds to an instance of fraud and 0 corresponds to an instance of not fraud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjECEDZ3kMMy"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y6WBQxrkMM3"
      },
      "source": [
        "### Question 1\n",
        "Import the data from `fraud_data.csv`. What percentage of the observations in the dataset are instances of fraud?\n",
        "\n",
        "*You should return a float between 0 and 1.* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A187d6RYUO4",
        "outputId": "ed671838-3ae8-4c11-d548-fcf8760ba667",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget http://www.eyrignoux.com.fr/coursIA/machineLearning/fraud_data.csv"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-30 14:53:33--  http://www.eyrignoux.com.fr/coursIA/machineLearning/fraud_data.csv\n",
            "Resolving www.eyrignoux.com.fr (www.eyrignoux.com.fr)... 62.210.16.62\n",
            "Connecting to www.eyrignoux.com.fr (www.eyrignoux.com.fr)|62.210.16.62|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.eyrignoux.com.fr/coursIA/machineLearning/fraud_data.csv [following]\n",
            "--2022-05-30 14:53:33--  https://www.eyrignoux.com.fr/coursIA/machineLearning/fraud_data.csv\n",
            "Connecting to www.eyrignoux.com.fr (www.eyrignoux.com.fr)|62.210.16.62|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11686383 (11M) [text/csv]\n",
            "Saving to: ‘fraud_data.csv.3’\n",
            "\n",
            "fraud_data.csv.3    100%[===================>]  11.14M  6.48MB/s    in 1.7s    \n",
            "\n",
            "2022-05-30 14:53:35 (6.48 MB/s) - ‘fraud_data.csv.3’ saved [11686383/11686383]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmITvoYIkMM4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14110ad0-f232-4629-cb13-080d630bbf3c"
      },
      "source": [
        "def answer_one():\n",
        "    df = pd.read_csv('fraud_data.csv')\n",
        "    pct = df[df['Class']==1].size / df.size\n",
        "    \n",
        "    return pct\n",
        "\n",
        "answer_one()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.016410823768035772"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU78eGxMkMM-"
      },
      "source": [
        "# Use X_train, X_test, y_train, y_test for all of the following questions\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('fraud_data.csv')\n",
        "\n",
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6yVyTWckMNC"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is the accuracy of this classifier? What is the recall?\n",
        "\n",
        "*You should a return a tuple with two floats, i.e. `(accuracy score, recall score)`.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiTTcdS4kMND",
        "outputId": "a2d3a031-54ae-4968-8398-711500952a1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "def answer_two():\n",
        "\n",
        "\n",
        "    dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
        "    accuracy = dummy_majority.score(X_test, y_test)\n",
        "        \n",
        "    predicted = dummy_majority.predict(X_test)\n",
        "    recall = recall_score(y_test, predicted)\n",
        "    \n",
        "    return (accuracy, recall)\n",
        "    \n",
        "answer_two()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9852507374631269, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0T2LB2RkMNJ"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "Using X_train, X_test, y_train, y_test (as defined above), train a SVC classifer using the default parameters. What is the accuracy, recall, and precision of this classifier?\n",
        "\n",
        "*You should a return a tuple with three floats, i.e. `(accuracy score, recall score, precision score)`.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCPazgB2kMNK",
        "outputId": "b5b71c0c-34a2-4880-eace-6633652e6a18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import recall_score, precision_score\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "def answer_three():\n",
        "\n",
        "    svc = SVC().fit(X_train, y_train)\n",
        "    accuracy = svc.score(X_test, y_test)\n",
        "        \n",
        "    predicted = svc.predict(X_test)\n",
        "    recall = recall_score(y_test, predicted)\n",
        "    precision = precision_score(y_test, predicted)\n",
        "    \n",
        "    return (accuracy, recall, precision)\n",
        "\n",
        "answer_three()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9900442477876106, 0.35, 0.9333333333333333)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUsBwzY_kMNO"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "Using the SVC classifier with parameters `{'C': 1e9, 'gamma': 1e-07}`, what is the confusion matrix when using a threshold of -220 on the decision function. Use X_test and y_test.\n",
        "\n",
        "*You should return a confusion matrix, a 2x2 numpy array with 4 integers.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hykMcHOgkMNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5951b40f-c91f-480b-b717-c0f92cdfd4f3"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "def answer_four():\n",
        "\n",
        "    svc = SVC(C=1e9, gamma=1e-07).fit(X_train, y_train)\n",
        "    y_scores = svc.decision_function(X_test)\n",
        "    predicted = [0 if score < -220 else 1 for score in y_scores]\n",
        "    \n",
        "    confusion = confusion_matrix(y_test, predicted)\n",
        "    \n",
        "    return confusion\n",
        "    \n",
        "answer_four()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5320,   24],\n",
              "       [  14,   66]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKFJOW1nkMNT"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "Train a logistic regression classifier with default parameters using X_train and y_train.\n",
        "\n",
        "For the logistic regression classifier, create a precision recall curve and a roc curve using y_test and the probability estimates for X_test (probability it is fraud).\n",
        "\n",
        "Looking at the precision recall curve, what is the recall when the precision is `0.75`?\n",
        "\n",
        "Looking at the roc curve, what is the true positive rate when the false positive rate is `0.16`?\n",
        "\n",
        "*This function should return a tuple with two floats, i.e. `(recall, true positive rate)`.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7HUe95HkMNT",
        "outputId": "c99270d1-464a-4e36-d561-51808bcb7119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "def plot_answer_five():\n",
        "    from sklearn.metrics import precision_recall_curve\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.metrics import roc_curve, auc\n",
        "    \n",
        "    # Your code here\n",
        "    clf = LogisticRegression().fit(X_train, y_train)\n",
        "    \n",
        "    clf_predicted = clf.decision_function(X_test)\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, clf_predicted)\n",
        "\n",
        "    closest_zero = np.argmin(np.abs(thresholds))\n",
        "    closest_zero_p = precision[closest_zero]\n",
        "    closest_zero_r = recall[closest_zero]\n",
        "\n",
        "    plt.figure()\n",
        "    plt.xlim([0.0, 1.01])\n",
        "    plt.ylim([0.0, 1.01])\n",
        "    plt.plot(precision, recall, label='Precision-Recall Curve')\n",
        "    plt.plot(closest_zero_p, closest_zero_r, 'o', markersize = 12, fillstyle = 'none', c='r', mew=3)\n",
        "    plt.xlabel('Precision', fontsize=16)\n",
        "    plt.ylabel('Recall', fontsize=16)\n",
        "    plt.axes().set_aspect('equal')\n",
        "    plt.show()\n",
        "    \n",
        "    fpr_lr, tpr_lr, _ = roc_curve(y_test, clf_predicted)\n",
        "    roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.xlim([-0.01, 1.00])\n",
        "    plt.ylim([-0.01, 1.01])\n",
        "    plt.plot(fpr_lr, tpr_lr, lw=3, label='LogRegr ROC curve (area = {:0.2f})'.format(roc_auc_lr))\n",
        "    plt.xlabel('False Positive Rate', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate', fontsize=16)\n",
        "    plt.title('ROC curve (1-of-10 digits classifier)', fontsize=16)\n",
        "    plt.legend(loc='lower right', fontsize=13)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=3, linestyle='--')\n",
        "    plt.axes().set_aspect('equal')\n",
        "    plt.show()\n",
        "\n",
        "plot_answer_five()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE7RiH_mkMNW",
        "outputId": "693bcf36-7e9a-4ca8-851e-2ed8b20893bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def answer_five():\n",
        "    return (0.8, 0.95)\n",
        "    \n",
        "answer_five()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8, 0.95)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RLdcK50kMNa"
      },
      "source": [
        "### Question 6\n",
        "\n",
        "Perform a grid search over the parameters listed below for a Logisitic Regression classifier, using recall for scoring and the default 3-fold cross validation.\n",
        "\n",
        "`'penalty': ['l1', 'l2']`\n",
        "\n",
        "`'C':[0.01, 0.1, 1, 10, 100]`\n",
        "\n",
        "From `.cv_results_`, create an array of the mean test scores of each parameter combination. i.e.\n",
        "\n",
        "|      \t| `l1` \t| `l2` \t|\n",
        "|:----:\t|----\t|----\t|\n",
        "| **`0.01`** \t|    ?\t|   ? \t|\n",
        "| **`0.1`**  \t|    ?\t|   ? \t|\n",
        "| **`1`**    \t|    ?\t|   ? \t|\n",
        "| **`10`**   \t|    ?\t|   ? \t|\n",
        "| **`100`**   \t|    ?\t|   ? \t|\n",
        "\n",
        "<br>\n",
        "\n",
        "*This function should return a 5 by 2 numpy array with 10 floats.* \n",
        "\n",
        "*Note: do not return a DataFrame, just the values denoted by '?' above in a numpy array. You might need to reshape your raw result to meet the format we are looking for.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXGroc_5kMNa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f2f8e832-3cf4-4060-e84f-7f1d6e462c68"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Your code here\n",
        "result = None\n",
        "    "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "50 fits failed out of a total of 100.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "50 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 436, in _check_solver\n",
            "    % (all_solvers, solver)\n",
            "ValueError: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got lbgfs.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan 0.34448052        nan 0.35175325        nan 0.35175325\n",
            "        nan 0.35175325        nan 0.35175325        nan 0.35175325\n",
            "        nan 0.35175325        nan 0.35175325        nan 0.35175325\n",
            "        nan 0.35175325]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-98de2d9c761b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0manswer_six\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-98de2d9c761b>\u001b[0m in \u001b[0;36manswer_six\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mgrid_clf_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mgrid_clf_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_clf_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 20 into shape (5,2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b4ludXQkMNf",
        "outputId": "2083f8f0-055e-4b69-b299-878414613bae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Use the following function to help visualize results from the grid search\n",
        "def GridSearch_Heatmap(scores):\n",
        "    import seaborn as sns\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure()\n",
        "    sns.heatmap(scores.reshape(5,2), xticklabels=['l1','l2'], yticklabels=[0.01, 0.1, 1, 10, 100])\n",
        "    plt.yticks(rotation=0);\n",
        "\n",
        "GridSearch_Heatmap(answer_six())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-d8fba8d561ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mGridSearch_Heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer_six\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-98de2d9c761b>\u001b[0m in \u001b[0;36manswer_six\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# default metric to optimize over grid parameters: accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mgrid_clf_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mgrid_clf_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_clf_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1612\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             )\n\u001b[0;32m-> 1614\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_coef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m         )\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    876\u001b[0m                 \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m                 \u001b[0mwarm_start_sag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m                 \u001b[0mis_saga\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"saga\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m             )\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[0;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mintercept_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mis_saga\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     )\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_cKSHLOkMNh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}